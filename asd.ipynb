{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = 'FB'\n",
    "start = dt.datetime(2012,1,1)\n",
    "end = dt.datetime(2020,1,1)\n",
    "\n",
    "data = web.DataReader(company, 'yahoo', start, end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Data\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(data['Close'].values.reshape(-1,1))\n",
    "\n",
    "prediction_days = 60\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for x in range(prediction_days, len(scaled_data)):\n",
    "    x_train.append(scaled_data[x-prediction_days:x, 0 ])\n",
    "    y_train.append(scaled_data[x,0])\n",
    "\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "6/6 [==============================] - 3s 47ms/step - loss: 0.0716\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0254\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0231\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0126\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0143\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0105\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0100\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0091\n",
      "Epoch 9/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0105\n",
      "Epoch 10/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0096\n",
      "Epoch 11/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0087\n",
      "Epoch 12/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0105\n",
      "Epoch 13/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0071\n",
      "Epoch 14/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0095\n",
      "Epoch 15/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0083\n",
      "Epoch 16/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0090\n",
      "Epoch 17/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0067\n",
      "Epoch 18/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0084\n",
      "Epoch 19/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0084\n",
      "Epoch 20/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0078\n",
      "Epoch 21/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0079\n",
      "Epoch 22/25\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0075\n",
      "Epoch 23/25\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0089\n",
      "Epoch 24/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0080\n",
      "Epoch 25/25\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0077\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[170.88000488 162.88000488 163.27000427 163.49000549 158.05000305\n 164.69999695 167.22999573 175.77999878 183.08999634 183.16999817\n 169.27000427 166.6499939  159.1499939  169.58000183 160.72000122\n 159.1000061  159.92999268 160.19000244 168.80000305 170.57000732\n 167.11000061 170.25       168.52999878 178.33999634 177.49000549\n 180.5        180.88999939 179.47000122 174.8500061  174.66000366\n 167.96000671 163.05000305 161.11000061 163.25999451 168.77999878\n 161.77999878 159.16999817 157.16000366 162.92999268 165.36000061\n 160.32000732 158.53999329 160.38999939 162.05999756 169.1499939\n 168.96000671 153.13000488 151.47000122 149.55000305 146.28999329\n 148.02000427 146.08999634 142.11999512 142.82000732 140.41000366\n 136.36999512 134.3999939  141.61000061 136.41000366 135.67999268\n 343.01000977 326.23001099 332.95999146 333.64001465 329.22000122\n 330.04998779 325.45001221 323.76998901 324.54000854 328.52999878\n 324.76000977 335.33999634 339.98999023 340.77999878 341.88000488\n 324.60998535 328.69000244 315.80999756 312.22000122 316.92001343\n 323.57000732 329.98001099 328.07998657 331.61999512 335.8500061\n 341.13000488 338.61999512 335.36999512 327.64001465 327.73999023\n 340.89001465 347.55999756 342.95999146 340.76998901 338.69000244\n 345.29998779 341.01000977 337.25       341.05999756 333.11999512\n 338.02999878 324.45999146 310.6000061  310.39001465 306.83999634\n 317.86999512 322.80999756 330.55999756 329.82000732 329.75\n 334.48999023 333.73999023 341.66000366 334.8999939  333.79000854\n 325.45001221 334.20001221 330.45001221 335.23999023 346.17999268\n 346.22000122 342.94000244 344.35998535 336.3500061  338.54000854\n 336.52999878 324.17001343 332.45999146 331.79000854 328.07000732\n 334.36999512 333.26000977 326.48001099 331.8999939  318.1499939\n 319.58999634 316.55999756 303.17001343 308.70999146 300.1499939\n 294.63000488 294.64001465 301.70999146 313.26000977 319.\n 323.         237.75999451 237.08999634 224.91000366 220.17999268\n 232.         228.07000732 219.55000305 217.69999695 221.\n 216.53999329 207.71000671 206.16000366 202.08000183 198.44999695\n 207.6000061  210.47999573 211.02999878 203.49000549 208.11000061\n 202.97000122 200.05999756 187.47000122 190.28999329 198.5\n 195.21000671 187.61000061 186.63000488 192.02999878 203.63000488\n 207.83999634 216.49000549 211.49000549 216.6499939  213.46000671\n 219.57000732 221.82000732 223.58999634 229.86000061 227.8500061\n 222.36000061 224.8500061  233.88999939 231.83999634 223.30000305\n 222.94999695 222.33000183 216.46000671 214.13999939 214.99000549\n 210.17999268 210.77000427 217.30999756 200.41999817 188.07000732\n 184.11000061 186.99000549 180.94999695 174.94999695 205.72999573\n 200.47000122 211.13000488 212.02999878 223.41000366 208.27999878\n 203.77000427 196.21000671 197.6499939  188.74000549 191.24000549\n 198.61999512 200.03999329 202.61999512 192.24000549 191.28999329\n 193.53999329 196.22999573 181.27999878 183.83000183 191.63000488\n 195.13000488 193.63999939 188.63999939 198.86000061 190.77999878\n 194.25       195.6499939  196.63999939 184.         175.57000732\n 164.25999451 163.72999573 169.3500061  160.86999512 163.74000549\n 157.05000305 155.8500061  158.75       170.16000366 169.49000549\n 160.67999268 163.94000244 161.25       160.02999878 168.19000244\n 169.77000427 172.19000244 170.88000488 162.88000488 163.27000427\n 163.49000549 158.05000305 164.69999695 167.22999573 175.77999878\n 183.08999634 183.16999817 169.27000427 166.6499939  159.1499939\n 169.58000183 160.72000122 159.1000061  159.92999268 160.19000244\n 168.80000305 170.57000732 167.11000061 170.25       168.52999878\n 178.33999634 177.49000549 180.5        180.88999939 179.47000122\n 174.8500061  174.66000366 167.96000671 163.05000305 161.11000061\n 163.25999451 168.77999878 161.77999878 159.16999817 157.16000366\n 162.92999268 165.36000061 160.32000732 158.53999329 160.38999939\n 162.05999756 169.1499939  168.96000671 153.13000488 151.47000122\n 149.55000305 146.28999329 148.02000427 146.08999634 142.11999512\n 142.82000732 140.41000366 136.36999512 134.3999939  141.61000061\n 136.41000366 135.67999268].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [26], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m total_dataset[\u001b[38;5;28mlen\u001b[39m(total_dataset) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_data) \u001b[38;5;241m-\u001b[39m prediction_days:]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     32\u001b[0m model_inputs \u001b[38;5;241m-\u001b[39m model_inputs\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(model_inputs)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#Make predictions on test data\u001b[39;00m\n\u001b[0;32m     37\u001b[0m x_test \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\owena\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:499\u001b[0m, in \u001b[0;36mMinMaxScaler.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[39m\"\"\"Scale features of X according to feature_range.\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \n\u001b[0;32m    487\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39m    Transformed data.\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    497\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 499\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    500\u001b[0m     X,\n\u001b[0;32m    501\u001b[0m     copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy,\n\u001b[0;32m    502\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    503\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    504\u001b[0m     reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    505\u001b[0m )\n\u001b[0;32m    507\u001b[0m X \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale_\n\u001b[0;32m    508\u001b[0m X \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_\n",
      "File \u001b[1;32mc:\\Users\\owena\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\owena\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    878\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 879\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    880\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    881\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    882\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    884\u001b[0m         )\n\u001b[0;32m    886\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    887\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    888\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    889\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    890\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[170.88000488 162.88000488 163.27000427 163.49000549 158.05000305\n 164.69999695 167.22999573 175.77999878 183.08999634 183.16999817\n 169.27000427 166.6499939  159.1499939  169.58000183 160.72000122\n 159.1000061  159.92999268 160.19000244 168.80000305 170.57000732\n 167.11000061 170.25       168.52999878 178.33999634 177.49000549\n 180.5        180.88999939 179.47000122 174.8500061  174.66000366\n 167.96000671 163.05000305 161.11000061 163.25999451 168.77999878\n 161.77999878 159.16999817 157.16000366 162.92999268 165.36000061\n 160.32000732 158.53999329 160.38999939 162.05999756 169.1499939\n 168.96000671 153.13000488 151.47000122 149.55000305 146.28999329\n 148.02000427 146.08999634 142.11999512 142.82000732 140.41000366\n 136.36999512 134.3999939  141.61000061 136.41000366 135.67999268\n 343.01000977 326.23001099 332.95999146 333.64001465 329.22000122\n 330.04998779 325.45001221 323.76998901 324.54000854 328.52999878\n 324.76000977 335.33999634 339.98999023 340.77999878 341.88000488\n 324.60998535 328.69000244 315.80999756 312.22000122 316.92001343\n 323.57000732 329.98001099 328.07998657 331.61999512 335.8500061\n 341.13000488 338.61999512 335.36999512 327.64001465 327.73999023\n 340.89001465 347.55999756 342.95999146 340.76998901 338.69000244\n 345.29998779 341.01000977 337.25       341.05999756 333.11999512\n 338.02999878 324.45999146 310.6000061  310.39001465 306.83999634\n 317.86999512 322.80999756 330.55999756 329.82000732 329.75\n 334.48999023 333.73999023 341.66000366 334.8999939  333.79000854\n 325.45001221 334.20001221 330.45001221 335.23999023 346.17999268\n 346.22000122 342.94000244 344.35998535 336.3500061  338.54000854\n 336.52999878 324.17001343 332.45999146 331.79000854 328.07000732\n 334.36999512 333.26000977 326.48001099 331.8999939  318.1499939\n 319.58999634 316.55999756 303.17001343 308.70999146 300.1499939\n 294.63000488 294.64001465 301.70999146 313.26000977 319.\n 323.         237.75999451 237.08999634 224.91000366 220.17999268\n 232.         228.07000732 219.55000305 217.69999695 221.\n 216.53999329 207.71000671 206.16000366 202.08000183 198.44999695\n 207.6000061  210.47999573 211.02999878 203.49000549 208.11000061\n 202.97000122 200.05999756 187.47000122 190.28999329 198.5\n 195.21000671 187.61000061 186.63000488 192.02999878 203.63000488\n 207.83999634 216.49000549 211.49000549 216.6499939  213.46000671\n 219.57000732 221.82000732 223.58999634 229.86000061 227.8500061\n 222.36000061 224.8500061  233.88999939 231.83999634 223.30000305\n 222.94999695 222.33000183 216.46000671 214.13999939 214.99000549\n 210.17999268 210.77000427 217.30999756 200.41999817 188.07000732\n 184.11000061 186.99000549 180.94999695 174.94999695 205.72999573\n 200.47000122 211.13000488 212.02999878 223.41000366 208.27999878\n 203.77000427 196.21000671 197.6499939  188.74000549 191.24000549\n 198.61999512 200.03999329 202.61999512 192.24000549 191.28999329\n 193.53999329 196.22999573 181.27999878 183.83000183 191.63000488\n 195.13000488 193.63999939 188.63999939 198.86000061 190.77999878\n 194.25       195.6499939  196.63999939 184.         175.57000732\n 164.25999451 163.72999573 169.3500061  160.86999512 163.74000549\n 157.05000305 155.8500061  158.75       170.16000366 169.49000549\n 160.67999268 163.94000244 161.25       160.02999878 168.19000244\n 169.77000427 172.19000244 170.88000488 162.88000488 163.27000427\n 163.49000549 158.05000305 164.69999695 167.22999573 175.77999878\n 183.08999634 183.16999817 169.27000427 166.6499939  159.1499939\n 169.58000183 160.72000122 159.1000061  159.92999268 160.19000244\n 168.80000305 170.57000732 167.11000061 170.25       168.52999878\n 178.33999634 177.49000549 180.5        180.88999939 179.47000122\n 174.8500061  174.66000366 167.96000671 163.05000305 161.11000061\n 163.25999451 168.77999878 161.77999878 159.16999817 157.16000366\n 162.92999268 165.36000061 160.32000732 158.53999329 160.38999939\n 162.05999756 169.1499939  168.96000671 153.13000488 151.47000122\n 149.55000305 146.28999329 148.02000427 146.08999634 142.11999512\n 142.82000732 140.41000366 136.36999512 134.3999939  141.61000061\n 136.41000366 135.67999268].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Build the Model\n",
    "\n",
    "model = Sequential ()\n",
    "\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(x_train, y_train, epochs=25, batch_size=32)\n",
    "\n",
    "\n",
    "\n",
    "#TESTING THE MODEL\n",
    "\n",
    "\n",
    "test_start = dt.datetime(2020,1,1)\n",
    "test_end = dt.datetime(2021,1,1)\n",
    "\n",
    "test_data = web.DataReader(company, 'yahoo', test_start,  test_end)\n",
    "actual_prices = test_data['Close'].values\n",
    "\n",
    "total_dataset = pd.concat((data['Close'], test_data['Close']), axis=0)\n",
    "\n",
    "\n",
    "model_inputs = total_dataset[len(total_dataset) - len(test_data) - prediction_days:].values\n",
    "model_inputs - model_inputs.reshape(-1, 1)\n",
    "model_inputs = scaler.transform(model_inputs)\n",
    "\n",
    "#Make predictions on test data\n",
    "\n",
    "x_test = []\n",
    "\n",
    "for x in range(prediction_days, len(model_inputs)):\n",
    "    x_test.append(model_inputs[x-prediction_days:x, 0 ])\n",
    "\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "predicted_prices = model.predict(x_test)\n",
    "predicted_prices = scaler.inverse_transform(predicted_prices)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#PLOT\n",
    "\n",
    "plt.plot(actual_prices, color='black')\n",
    "plt.plot(predicted_prices, color='green')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46b1d01e68104ec17620421dbe5949478624b8a84c417070bb164efc7619deca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
